{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning convolutional neural networks\n",
    "Use this notebook to fine-tune pre-trained networks from Keras found here https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Import packages in cell 1.\n",
    "2. Comment with enough detail to understand what the utility functions do in cell 2.\n",
    "3. Pre-process data, completing code with TO DO statements above them in cell 3\n",
    "4. Build, compile, and train model, completing code with TO DO statements in cell 4 (4a and 4b)\n",
    "5. Predict how well model did, completing code with TO DO statements in cell 5\n",
    "6. Use this notebook as a template to fine tune a different pre-trained model architecture (found at https://keras.io/applications/), making adjustments for that model as necessary\n",
    "7. Compare performance for at least 3 model architectures and document which is the best to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from random import shuffle\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Imports for deep learning specifically\n",
    "from keras.applications.inception_v3 import InceptionV3#--[don't need if running Xception]\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,  Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining utility functions\n",
    "Do NOT change the functions in this cell, ONLY comment as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(root_dir, img_types):\n",
    "    #os.walk creates 3-tuple with (dirpath, dirnames, filenames)\n",
    "    \n",
    "    # Get all the root directories, subdirectories, and files\n",
    "    full_paths = [x for x in os.walk(root_dir)] \n",
    "    imgs_temp = [os.path.join(ds,f) for ds,_,fs in full_paths for f in fs if f]   \n",
    "    \n",
    "    # Filter out so only have directories with .jpg, .tiff, .tif, .png, .jpeg\n",
    "    imgs = [j for j in imgs_temp if any (k in j for k in img_types)]\n",
    "    return imgs\n",
    "\n",
    "def get_dimensions(files):\n",
    "    # Set starting points for min and max dimensions\n",
    "    min_height, min_width = 10000, 10000\n",
    "    max_height, max_width = 0, 0\n",
    "    \n",
    "    for f in files:\n",
    "        # Read in images\n",
    "        img = cv.imread(f) # Read in images\n",
    "        h,w = img.shape[:2] # get height and width\n",
    "        \n",
    "        # Update min and max values, if necessary\n",
    "        if h < min_height:\n",
    "            min_height = h \n",
    "        if h > max_height:\n",
    "            max_height = h\n",
    "        if w < min_width:\n",
    "            min_width = w\n",
    "        if w > max_width:\n",
    "            max_width = w\n",
    "            \n",
    "    return min_height, min_width, max_height, max_width\n",
    "\n",
    "def make_labels(files):\n",
    "    # Assume input is a list of complete file paths.\n",
    "    # Count the number of unique directory names that are immediate parent of the files.\n",
    "    # Order the directory names alphabetically from a-z, and associate labels accordingly.\n",
    "    set_temp = {x.split('/')[-2] for x in files} #doing as set to get only unique values\n",
    "    list_temp = list(set_temp) #Change to list so can interate over it\n",
    "    list_new = sorted(list_temp) #Alphabetizing\n",
    "    label_dict = {list_new[x]:x for x in range(len(list_new))} #create dictionary with category:index\n",
    "    \n",
    "    return label_dict\n",
    "\n",
    "\n",
    "def make_train_val_test(files, labels):\n",
    "    train=[]\n",
    "    valid = []\n",
    "    test =[]\n",
    "    train_labels_name = []\n",
    "    valid_labels_name = []\n",
    "    test_labels_name = []\n",
    "    train_prop = 0.6 #proportion of data set that will be training\n",
    "    val_prop = 0.2 #proprotion of dataset that is validation\n",
    "    for key in labels: #going through each key\n",
    "        temp = [f for f in files if key in f] #getting all files in a specific category (ie key)\n",
    "        lower_prop = math.ceil(train_prop*len(temp))\n",
    "        train.extend(temp[:lower_prop]) #training data set\n",
    "        valid.extend(temp[lower_prop:lower_prop+math.ceil(val_prop*len(temp))]) # validation data set\n",
    "        test.extend(temp[lower_prop+math.ceil(val_prop*len(temp)):])\n",
    "    train_labels_name = [x.split('/')[-2] for x in train]\n",
    "    valid_labels_name = [x.split('/')[-2] for x in valid]\n",
    "    test_labels_name =  [x.split('/')[-2] for x in test]\n",
    "    return train, valid, test, train_labels_name, valid_labels_name, test_labels_name\n",
    "\n",
    "\n",
    "def get_batches(files, label_map, batch_size, resize_size, num_color_channels, augment=False, predict=False, do_shuffle = True):\n",
    "    if do_shuffle:\n",
    "        shuffle(files)\n",
    "    count = 0\n",
    "    num_files = len(files)\n",
    "    num_classes = len(label_map)\n",
    "    \n",
    "    batch_out = np.zeros((batch_size, resize_size[0], resize_size[1], num_color_channels), dtype=np.uint8)\n",
    "    labels_out = np.zeros((batch_size,num_classes)) #one-hot labeling, which is why have num_classes num of col.   \n",
    "\n",
    "    while True: # while True is to ensure when yielding that start here and not previous lines\n",
    "\n",
    "        f = files[count]\n",
    "        img = cv.imread(f)       \n",
    "\n",
    "        # Resize\n",
    "        # First resize while keeping aspect ratio\n",
    "        rows,cols = img.shape[:2] # Define in input num_color_channels in case want black and white\n",
    "        rc_ratio = rows/cols\n",
    "        if resize_size[0] > int(resize_size[1]*rc_ratio):# if resize rows > rows with given aspect ratio\n",
    "            img = cv.resize(img, (resize_size[1], int(resize_size[1]*rc_ratio)))#NB: resize dim arg are col,row\n",
    "        else:\n",
    "            img = cv.resize(img, (int(resize_size[0]/rc_ratio), resize_size[0]))\n",
    "            \n",
    "        # Second, pad to final size\n",
    "        rows,cols = img.shape[:2] #find new num rows and col of resized image\n",
    "        res = np.zeros((resize_size[0], resize_size[1], num_color_channels), dtype=np.uint8)#array of zeros\n",
    "        res[(resize_size[0]-rows)//2:(resize_size[0]-rows)//2+rows,\n",
    "            (resize_size[1]-cols)//2:(resize_size[1]-cols)//2+cols,:] = img # fill in image in middle of zeros\n",
    "                \n",
    "        # Augmentation \n",
    "        if augment:            \n",
    "            rows,cols = res.shape[:2]\n",
    "            # calculates affine rotation with random angle rotation, keeping same center and scale\n",
    "            M = cv.getRotationMatrix2D((cols/2,rows/2),np.random.uniform(0.0,360.0,1),1) \n",
    "            # applies affine rotation\n",
    "            res = cv.warpAffine(res,M,(cols,rows))\n",
    "\n",
    "        # Change to gray scale if input argument num_color_channels = 1\n",
    "        if num_color_channels == 1: \n",
    "            res = cv.cvtColor(res, cv.COLOR_BGR2GRAY)# convert from bgr to gray\n",
    "            res = res[...,None] # add extra dimension with blank values to very end, needed for keras\n",
    "            \n",
    "        batch_out[count%batch_size,...] = res # put image in position in batch, never to exceed size of batch\n",
    "        \n",
    "        for k in label_map.keys():\n",
    "            if k in f: #if a category name is found in the path to the file of the image\n",
    "                labels_out[count%batch_size,:] = np_utils.to_categorical(label_map[k],num_classes) #one hot labeling\n",
    "                break   \n",
    "                \n",
    "        count += 1\n",
    "        if count == num_files:# if gone through all files, restart the counter\n",
    "            count = 0\n",
    "        if count%batch_size == 0: #if gone through enough files to make a full batch\n",
    "            if predict: # i.e., there is no label for this batch of images, so in prediction mode\n",
    "                yield batch_out.astype(np.float)/255.\n",
    "            else: # training\n",
    "                yield batch_out.astype(np.float)/255., labels_out\n",
    "            \n",
    "            \n",
    "            \n",
    "def convert_to_class(prediction,label_map):\n",
    "    predict_max = np.argmax(prediction,axis=1)#provides index of max value out of prediction classes\n",
    "    predict_label = []\n",
    "    for i in range(len(predict_max)):\n",
    "        for k,v in label_map.items():\n",
    "                if predict_max[i] == v:\n",
    "                    predict_label.append(k)\n",
    "    return predict_label    \n",
    "\n",
    "def prop_correct(predict_label,actual_label):\n",
    "    correct_class = []\n",
    "    for i in range(len(predict_label)):\n",
    "        if predict_label[i]==actual_label[i]:\n",
    "            correct_class.append(1)\n",
    "        else:\n",
    "            correct_class.append(0)\n",
    "    num_correct = sum(correct_class)\n",
    "    proportion_correct = num_correct/len(predict_label)\n",
    "    return proportion_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files is  0\n",
      "example file names are  []\n",
      "Over all images - minimum height: 10000, minimum width: 10000, maximum height: 0, maximum width:0\n",
      "{}\n",
      "length of trainig data is  13\n",
      "length of trainig data is  15\n",
      "length of trainig data is  12\n",
      "train labels length is  15\n",
      "validation labels length is 17\n",
      "test labels length is 19\n"
     ]
    }
   ],
   "source": [
    "# Get full paths to all classification data\n",
    "# Data is assumed to reside under the directory \"root_dir\", and data for each class is assumed to reside in a separate subfolder\n",
    "\n",
    "# TO DO: define in the variable root_dir the directory path to where the folders with the images are located\n",
    "root_dir = '/home/guest_3/Desktop/Image_classification_SPCS/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other'\n",
    "\n",
    "\n",
    "# TO DO: add in any additional image types in path above that are not already listed in the img_types variable below\n",
    "img_types=['.jpg', '.tiff', '.tif', '.png', '.jpeg']\n",
    "\n",
    "files = get_image_files(root_dir, img_types)\n",
    "print('number of files is ',len(files))\n",
    "print('example file names are ', files[0:4])\n",
    "\n",
    "# Get the dimension range of the data for informational purposes\n",
    "minh,minw,maxh,maxw = get_dimensions(files)\n",
    "print('Over all images - minimum height: {}, minimum width: {}, maximum height: {}, maximum width:{}'.format(minh,minw,maxh,maxw))\n",
    "\n",
    "# Assign numerical labels to categories - the number of categories is equal to the number of subfolders\n",
    "label_map = make_labels(files)\n",
    "print(label_map)\n",
    "\n",
    "# TO DO: Using the appropriate utility function from cell 2, divide data into training, validation, and testing data\n",
    "# Variable names should be as follows:\n",
    "train_files ='training data'\n",
    "val_files ='validation data'\n",
    "test_files ='testing data'\n",
    "train_labels_name = 'training labels'\n",
    "val_labels_name = 'validation labels'\n",
    "test_labels_name = 'testing data labels'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print length of each data set and labels array\n",
    "print('length of trainig data is ',len(train_files))\n",
    "print('length of trainig data is ',len(val_files))\n",
    "print('length of trainig data is ',len(test_files))\n",
    "\n",
    "print('train labels length is ',len(train_labels_name))\n",
    "print('validation labels length is', len(val_labels_name))\n",
    "print('test labels length is', len(test_labels_name))    \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine tuning\n",
    "The code below was modified from https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes and must be adapted for use with xception instead of InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Creating base pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base pre-trained model\n",
    "# TO DO: Think about if you should include the top layers (the layers used for classification in the ORIGINAL model). \n",
    "# If you should, type in include_top = True, otherwise, use include_top = False\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(4, activation='relu')(x)\n",
    "\n",
    "# Add logistic layer -- let's say we have x classes--determined by len(label_map)\n",
    "predictions = Dense(len(label_map), activation='softmax')(x)\n",
    "\n",
    "# Below is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done AFTER setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Training existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-189b06e68d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#one-hot encoded data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-72e011c248ae>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(files, label_map, batch_size, resize_size, num_color_channels, augment, predict, do_shuffle)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_color_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_shuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mnum_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/random.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "## TO DO: try the following batch sizes, one at a time: 16, 32, 64, recording accuracy for all\n",
    "BS = 32\n",
    "\n",
    "# Initializing other parameters\n",
    "EPOCHS = 1000\n",
    "im_wid = 150\n",
    "im_height = 150 \n",
    "\n",
    "# Construct the training image generator for data augmentation\n",
    "data_gen = ImageDataGenerator(featurewise_center = False, samplewise_center = False,\n",
    "                             featurewise_std_normalization = False, samplewise_std_normalization=False,\n",
    "                             rotation_range = 360, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                             zoom_range = 0.5, fill_mode = 'constant',cval=0,horizontal_flip = True,\n",
    "                             vertical_flip = True, rescale = None)\n",
    "\n",
    "# Get array of training and validaiton images \n",
    "train_gen = get_batches(train_files, label_map, batch_size = len(train_files),resize_size=[im_height,im_wid],\n",
    "                       num_color_channels=3)\n",
    "val_gen = get_batches(val_files,label_map,batch_size = len(val_files),resize_size=[im_height,im_wid],\n",
    "                     num_color_channels = 3)\n",
    "\n",
    "\n",
    "train_data, train_labels_oh = next(train_gen) #one-hot encoded data\n",
    "val_data, val_labels_oh = next(val_gen)\n",
    "\n",
    "# Train the network\n",
    "ES = EarlyStopping(monitor='val_loss',patience=20,verbose=0)# callback to stop if validation loss has not improved in 20 iterations\n",
    "model.fit_generator(data_gen.flow(train_data,train_labels_oh, batch_size = BS),\n",
    "                   steps_per_epoch=len(train_files)//BS,epochs = EPOCHS,\n",
    "                   validation_data=data_gen.flow(val_data,val_labels_oh,batch_size=BS),\n",
    "                   validation_steps = len(val_files)//BS,\n",
    "                   callbacks=[ES])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data\n",
    "predict_gen = get_batches(test_files,label_map,batch_size=1,resize_size=[im_height,im_wid],\n",
    "                          num_color_channels=3, predict = True,do_shuffle=False)\n",
    "prediction = model.predict_generator(predict_gen,steps = len(test_files))\n",
    "\n",
    "# TO DO: Use the appropriate utility function from cell 2 to convert predictions (saved in the variable prediction\n",
    "    # to a classification category\n",
    "    # Save the output in the variable predict_class\n",
    "\n",
    "    \n",
    "\n",
    "# TO DO: Determine the proportion of classifications that were classified correctly using the appropriate utility\n",
    "    # function from cell 2. Save that proportion in the variable proportion_correct\n",
    "    \n",
    "    \n",
    "# Printing proportion correct    \n",
    "print(proportion_correct)\n",
    "\n",
    "# TO DO: record the variable settings (e.g., CNN architecture, batch size, epochs, optimizers, and proportion correct) \n",
    "    # in some document (e.g., excel spreadsheet, git, etc.)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model and compiling first layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=(880,920,3), pooling=None)\n",
    "base_modelX = Xception(include_top=False, weights='imagenet')\n",
    "\n",
    "# Adding global spatial average pooling layer\n",
    "xX = base_modelX.output\n",
    "xX = GlobalAveragePooling2D()(xX)\n",
    "\n",
    "# Adding in fully-connected layer\n",
    "xX = Dense(4, activation='relu')(xX)\n",
    "\n",
    "# Logistic layer for number of classes\n",
    "## [Add in flexible number of classes]\n",
    "predictions = Dense(len(label_map),activation='softmax')(xX)\n",
    "\n",
    "# Model that will be trained\n",
    "modelX = Model(inputs = base_modelX.input, outputs = predictions)\n",
    "\n",
    "# Training only top layers\n",
    "for layer in base_modelX.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile model\n",
    "## [Choose different optimizers]\n",
    "modelX.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [Vary batch size, maybe epochs]\n",
    "EPOCHS = 1000\n",
    "BS = 32\n",
    "\n",
    "im_height = 150\n",
    "im_wid = 150\n",
    "\n",
    "# Creating training image generator for data augmentation\n",
    "data_gen = ImageDataGenerator(featurewise_center = False, samplewise_center = False, \n",
    "                             featurewise_std_normalization = False, samplewise_std_normalization = False,\n",
    "                             rotation_range = 360, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                             zoom_range = 0.5, fill_mode = 'constant',cval = 0, horizontal_flip = True,\n",
    "                             vertical_flip = True, rescale = None)\n",
    "\n",
    "# Getting training and validation generators\n",
    "train_gen = get_batches(train_files, label_map, batch_size = len(train_files),\n",
    "                       resize_size = [im_height,im_wid],num_color_channels=3)\n",
    "val_gen = get_batches(val_files, label_map,batch_size = len(val_files),\n",
    "                     resize_size = [im_height,im_wid],num_color_channels=3)\n",
    "train_data,train_labels_oh = next(batch_gen)\n",
    "val_data,val_labels_oh = next(val_gen)\n",
    "\n",
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
